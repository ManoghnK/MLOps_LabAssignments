{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "255fb0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b86dbf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "077b4eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.integration.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras as k\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaef52de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/rohit/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmanoghn\u001b[0m (\u001b[33mmanoghn-northeastern-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fd8496f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/rohit/Desktop/College/NEU/MLops/Labs/wandb/run-20251103_221011-mm21g6f0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/manoghn-northeastern-university/Lab1-visualize-models/runs/mm21g6f0' target=\"_blank\">cifar10_cnn</a></strong> to <a href='https://wandb.ai/manoghn-northeastern-university/Lab1-visualize-models' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/manoghn-northeastern-university/Lab1-visualize-models' target=\"_blank\">https://wandb.ai/manoghn-northeastern-university/Lab1-visualize-models</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/manoghn-northeastern-university/Lab1-visualize-models/runs/mm21g6f0' target=\"_blank\">https://wandb.ai/manoghn-northeastern-university/Lab1-visualize-models/runs/mm21g6f0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m155/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2209 - loss: 2.1171"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.2957 - loss: 1.9566 - val_accuracy: 0.3560 - val_loss: 1.8435\n",
      "Epoch 2/5\n",
      "\u001b[1m153/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4192 - loss: 1.6284"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.4387 - loss: 1.5820 - val_accuracy: 0.4076 - val_loss: 1.6349\n",
      "Epoch 3/5\n",
      "\u001b[1m156/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4841 - loss: 1.4535"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.4926 - loss: 1.4267 - val_accuracy: 0.4567 - val_loss: 1.5317\n",
      "Epoch 4/5\n",
      "\u001b[1m153/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5282 - loss: 1.3487"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.5254 - loss: 1.3510 - val_accuracy: 0.4976 - val_loss: 1.4247\n",
      "Epoch 5/5\n",
      "\u001b[1m149/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5368 - loss: 1.3085"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.5411 - loss: 1.3027 - val_accuracy: 0.5008 - val_loss: 1.4339\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>▁▂▂▃▃▃▃▄▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇███████▇█████████</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>batch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/loss</td><td>██▇▇▇▆▆▆▆▆▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁▅▇██</td></tr><tr><td>epoch/epoch</td><td>▁▃▅▆█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▄▂▂▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▃▆██</td></tr><tr><td>epoch/val_loss</td><td>█▅▃▁▁</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.5416</td></tr><tr><td>batch/batch_step</td><td>790</td></tr><tr><td>batch/learning_rate</td><td>0.01</td></tr><tr><td>batch/loss</td><td>1.30048</td></tr><tr><td>epoch/accuracy</td><td>0.5411</td></tr><tr><td>epoch/epoch</td><td>4</td></tr><tr><td>epoch/learning_rate</td><td>0.01</td></tr><tr><td>epoch/loss</td><td>1.30265</td></tr><tr><td>epoch/val_accuracy</td><td>0.5008</td></tr><tr><td>epoch/val_loss</td><td>1.43391</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cifar10_cnn</strong> at: <a href='https://wandb.ai/manoghn-northeastern-university/Lab1-visualize-models/runs/mm21g6f0' target=\"_blank\">https://wandb.ai/manoghn-northeastern-university/Lab1-visualize-models/runs/mm21g6f0</a><br> View project at: <a href='https://wandb.ai/manoghn-northeastern-university/Lab1-visualize-models' target=\"_blank\">https://wandb.ai/manoghn-northeastern-university/Lab1-visualize-models</a><br>Synced 4 W&B file(s), 10 media file(s), 193 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251103_221011-mm21g6f0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class LogLRCallback(k.callbacks.Callback):\n",
    "    \"\"\"Log optimizer learning rate each epoch.\"\"\"\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        opt = self.model.optimizer\n",
    "        lr = opt.learning_rate\n",
    "        lr_val = float(lr.numpy() if hasattr(lr, \"numpy\") else lr)\n",
    "        wandb.log({\"lr\": lr_val}, step=self.model.optimizer.iterations.numpy())\n",
    "\n",
    "class LogSamplesCallback(k.callbacks.Callback):\n",
    "    \"\"\"Log a small table of predictions + images every epoch.\"\"\"\n",
    "    def __init__(self, x, y, labels, max_rows=32):\n",
    "        super().__init__()\n",
    "        self.x = x[:max_rows]\n",
    "        self.y = y[:max_rows]\n",
    "        self.labels = labels\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        preds = self.model.predict(self.x, verbose=0)\n",
    "        y_true = np.argmax(self.y, axis=1)\n",
    "        y_pred = np.argmax(preds, axis=1)\n",
    "\n",
    "        table = wandb.Table(columns=[\"image\", \"y_true\", \"y_pred\", \"correct\", \"p(y_pred)\"])\n",
    "        for i in range(len(self.x)):\n",
    "            img = self.x[i]\n",
    "            table.add_data(\n",
    "                wandb.Image(img),\n",
    "                self.labels[y_true[i]],\n",
    "                self.labels[y_pred[i]],\n",
    "                bool(y_true[i] == y_pred[i]),\n",
    "                float(np.max(preds[i])),\n",
    "            )\n",
    "        wandb.log({f\"samples/epoch_{epoch+1}\": table})\n",
    "\n",
    "class ConfusionMatrixCallback(k.callbacks.Callback):\n",
    "    \"\"\"Log a confusion matrix from the full validation set each epoch.\"\"\"\n",
    "    def __init__(self, x_val, y_val, labels):\n",
    "        super().__init__()\n",
    "        self.x_val = x_val\n",
    "        self.y_val = y_val\n",
    "        self.labels = labels\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        preds = self.model.predict(self.x_val, verbose=0)\n",
    "        y_true = np.argmax(self.y_val, axis=1)\n",
    "        y_pred = np.argmax(preds, axis=1)\n",
    "        cm_plot = wandb.plot.confusion_matrix(\n",
    "            probs=None,\n",
    "            y_true=y_true,\n",
    "            preds=y_pred,\n",
    "            class_names=self.labels,\n",
    "        )\n",
    "        wandb.log({\"confusion_matrix\": cm_plot})\n",
    "\n",
    "# --- trainer -----------------------------------------------------------------\n",
    "\n",
    "class CIFAR10Trainer:\n",
    "    def __init__(self, project_name=\"Lab1-visualize-models\", run_name=\"cifar10_cnn\"):\n",
    "        self.cfg = dict(\n",
    "            dropout=0.2,\n",
    "            layer_1_size=32,\n",
    "            learn_rate=0.01,\n",
    "            momentum=0.9,\n",
    "            epochs=5,\n",
    "            batch_size=64,\n",
    "            sample=10000,\n",
    "        )\n",
    "        self.run = wandb.init(\n",
    "            project=project_name,\n",
    "            name=run_name,\n",
    "            config=self.cfg,\n",
    "            settings=wandb.Settings(start_method=\"thread\"),\n",
    "        )\n",
    "        self.config = wandb.config\n",
    "        # CIFAR-10 labels\n",
    "        self.labels = [\"Airplane\", \"Automobile\", \"Bird\", \"Cat\", \"Deer\",\n",
    "                       \"Dog\", \"Frog\", \"Horse\", \"Ship\", \"Truck\"]\n",
    "        self._prepare_data()\n",
    "\n",
    "    def _prepare_data(self):\n",
    "        # Load CIFAR-10 dataset\n",
    "        (xtr, ytr), (xte, yte) = cifar10.load_data()\n",
    "        n = self.config.sample\n",
    "        xtr = xtr[:n].astype(\"float32\")/255.0\n",
    "        ytr = ytr[:n].squeeze()  # CIFAR labels come as (n,1), squeeze to (n,)\n",
    "        xte = xte[:n].astype(\"float32\")/255.0\n",
    "        yte = yte[:n].squeeze()\n",
    "        \n",
    "        # CIFAR-10 images are 32x32x3 (RGB)\n",
    "        self.X_train = xtr\n",
    "        self.X_test  = xte\n",
    "        self.y_train = to_categorical(ytr)\n",
    "        self.y_test  = to_categorical(yte)\n",
    "        self.num_classes = self.y_test.shape[1]\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Updated input shape for CIFAR-10: 32x32x3\n",
    "        inputs = k.Input(shape=(32, 32, 3))\n",
    "        x = k.layers.Conv2D(self.config.layer_1_size, (5,5), activation=\"relu\")(inputs)\n",
    "        x = k.layers.MaxPooling2D((2,2))(x)\n",
    "        x = k.layers.Dropout(self.config.dropout)(x)\n",
    "        x = k.layers.Flatten()(x)\n",
    "        outputs = k.layers.Dense(self.num_classes, activation=\"softmax\")(x)\n",
    "        model = k.Model(inputs, outputs)\n",
    "\n",
    "        opt = k.optimizers.SGD(\n",
    "            learning_rate=self.config.learn_rate,\n",
    "            momentum=self.config.momentum,\n",
    "            nesterov=True,\n",
    "        )\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "        return model\n",
    "\n",
    "    def _log_model_artifact(self, model):\n",
    "        # model summary as a text file + the saved model as an artifact\n",
    "        summary_lines = []\n",
    "        model.summary(print_fn=summary_lines.append)\n",
    "        summary_txt = \"\\n\".join(summary_lines)\n",
    "        os.makedirs(\"artifacts\", exist_ok=True)\n",
    "        with open(\"artifacts/model_summary.txt\", \"w\") as f:\n",
    "            f.write(summary_txt)\n",
    "\n",
    "        model_path = \"artifacts/model.h5\"\n",
    "        model.save(model_path)\n",
    "\n",
    "        art = wandb.Artifact(\"cifar10_model\", type=\"model\")\n",
    "        art.add_file(\"artifacts/model_summary.txt\")\n",
    "        art.add_file(model_path)\n",
    "        self.run.log_artifact(art)\n",
    "\n",
    "    def train(self):\n",
    "        model = self._build_model()\n",
    "\n",
    "        callbacks = [\n",
    "            WandbMetricsLogger(log_freq=10),\n",
    "            WandbModelCheckpoint(\"checkpoints/model-{epoch:02d}.h5\", save_weights_only=False),\n",
    "            LogLRCallback(),\n",
    "            LogSamplesCallback(self.X_test, self.y_test, self.labels, max_rows=32),\n",
    "            ConfusionMatrixCallback(self.X_test, self.y_test, self.labels),\n",
    "        ]\n",
    "\n",
    "        model.fit(\n",
    "            self.X_train, self.y_train,\n",
    "            validation_data=(self.X_test, self.y_test),\n",
    "            epochs=self.config.epochs,\n",
    "            batch_size=self.config.batch_size,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1,\n",
    "        )\n",
    "\n",
    "        loss, acc = model.evaluate(self.X_test, self.y_test, verbose=0)\n",
    "        wandb.log({\"final/loss\": loss, \"final/accuracy\": acc})\n",
    "\n",
    "        self._log_model_artifact(model)\n",
    "\n",
    "        self.run.finish()\n",
    "\n",
    "\n",
    "# Run the trainer\n",
    "CIFAR10Trainer().train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
